{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of XOR gate using Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise implements the XOR Gate using tensorflow, by using just a single layer soft perceptron, with sigmoid activation, cost function and Gradient descent optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# removes warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing packages.\n",
    "import tensorflow as tf\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataset\n",
    "\n",
    "XOR_inp = [[0,0],[0,1],[1,0],[1,1]]\n",
    "XOR_op = [[0],[1],[1],[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating placeholders for datasets.\n",
    "\n",
    "x_ = tf.placeholder(tf.float32, shape=[4,2], name = 'x-input')\n",
    "y_ = tf.placeholder(tf.float32, shape=[4,1], name = 'y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating weights and biases\n",
    "\n",
    "Theta1 = tf.Variable(tf.random_uniform([2,1], -1, 1), name = \"Theta1\")\n",
    "# Theta2 = tf.Variable(tf.random_uniform([2,1], -1, 1), name = \"Theta2\")\n",
    "\n",
    "Bias1 = tf.Variable(tf.zeros([1]), name = \"Bias1\")\n",
    "# Bias2 = tf.Variable(tf.zeros([1]), name = \"Bias2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"soln\") as scope:\n",
    "    soln = tf.sigmoid(tf.matmul(x_, Theta1) + Bias1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining cost function = log loss\n",
    "\n",
    "with tf.name_scope(\"cost\") as scope:\n",
    "    cost = tf.reduce_mean(( (y_ * tf.log(soln)) + \n",
    "        ((1 - y_) * tf.log(1.0 - soln)) ) * -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining training operation.\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cost)# learning rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initilising variables and session.\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Result  [[0.5001064 ]\n",
      " [0.62447095]\n",
      " [0.2952955 ]\n",
      " [0.41055807]]\n",
      "Theta1  [[-0.8702277 ]\n",
      " [ 0.50814325]]\n",
      "Bias1  [0.00042564]\n",
      "cost  0.728142\n",
      "Epoch  1000\n",
      "Result  [[0.52066517]\n",
      " [0.594755  ]\n",
      " [0.4098224 ]\n",
      " [0.48406807]]\n",
      "Theta1  [[-0.44740722]\n",
      " [ 0.3009502 ]]\n",
      "Bias1  [0.08270765]\n",
      "cost  0.7021934\n",
      "Epoch  2000\n",
      "Result  [[0.5143773 ]\n",
      " [0.5523325 ]\n",
      " [0.45213214]\n",
      " [0.49012998]]\n",
      "Theta1  [[-0.24958481]\n",
      " [ 0.15257436]]\n",
      "Bias1  [0.05752511]\n",
      "cost  0.6958271\n",
      "Epoch  3000\n",
      "Result  [[0.5097166 ]\n",
      " [0.5284321 ]\n",
      " [0.47461492]\n",
      " [0.4933384 ]]\n",
      "Theta1  [[-0.14049904]\n",
      " [ 0.07497984]]\n",
      "Bias1  [0.0388712]\n",
      "cost  0.693944\n",
      "Epoch  4000\n",
      "Result  [[0.5065627 ]\n",
      " [0.5154451 ]\n",
      " [0.48661432]\n",
      " [0.49549812]]\n",
      "Theta1  [[-0.07980791]\n",
      " [ 0.03554745]]\n",
      "Bias1  [0.02625252]\n",
      "cost  0.69338775\n",
      "Epoch  5000\n",
      "Result  [[0.50443274]\n",
      " [0.50841236]\n",
      " [0.49297878]\n",
      " [0.49695876]]\n",
      "Theta1  [[-0.04581795]\n",
      " [ 0.01592147]]\n",
      "Bias1  [0.0177313]\n",
      "cost  0.6932217\n",
      "Epoch  6000\n",
      "Result  [[0.502994  ]\n",
      " [0.5045999 ]\n",
      " [0.4963398 ]\n",
      " [0.49794567]]\n",
      "Theta1  [[-0.02661733]\n",
      " [ 0.00642391]]\n",
      "Bias1  [0.01197623]\n",
      "cost  0.693171\n",
      "Epoch  7000\n",
      "Result  [[0.50202227]\n",
      " [0.50252765]\n",
      " [0.4981071 ]\n",
      " [0.49861246]]\n",
      "Theta1  [[-0.01566088]\n",
      " [ 0.00202151]]\n",
      "Bias1  [0.00808914]\n",
      "cost  0.69315517\n",
      "Epoch  8000\n",
      "Result  [[0.5013659 ]\n",
      " [0.5013972 ]\n",
      " [0.4990315 ]\n",
      " [0.49906275]]\n",
      "Theta1  [[-0.00933769]\n",
      " [ 0.00012518]]\n",
      "Bias1  [0.00546367]\n",
      "cost  0.69315\n",
      "Epoch  9000\n",
      "Result  [[0.5009226 ]\n",
      " [0.5007778 ]\n",
      " [0.49951178]\n",
      " [0.49936697]]\n",
      "Theta1  [[-0.00564328]\n",
      " [-0.00057916]]\n",
      "Bias1  [0.00369034]\n",
      "cost  0.6931482\n",
      "Elapsed time  2.545071\n"
     ]
    }
   ],
   "source": [
    "# Training the model - Forward Propagation\n",
    "\n",
    "t_start = time.clock()\n",
    "for i in range(10000):\n",
    "    sess.run(train_step, feed_dict={x_: XOR_inp, y_: XOR_op})\n",
    "    if i % 1000 == 0:\n",
    "        print('Epoch ', i)\n",
    "        print('Result ', sess.run(soln, feed_dict={x_: XOR_inp, y_: XOR_op}))\n",
    "        print('Theta1 ', sess.run(Theta1))\n",
    "        print('Bias1 ', sess.run(Bias1))\n",
    "        print('cost ', sess.run(cost, feed_dict={x_: XOR_inp, y_: XOR_op}))\n",
    "t_end = time.clock()\n",
    "\n",
    "print('Elapsed time ', t_end - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the run above, we can see that using just a single layer perceptron, \n",
    "# we cannot train the model to predict output for XOR gate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
