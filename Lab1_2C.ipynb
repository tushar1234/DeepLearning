{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of XOR gate using Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise implements the XOR Gate using tensorflow, via multi layer perceptrons, cost function and Gradient descent optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# removes warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing packages.\n",
    "import tensorflow as tf\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataset\n",
    "\n",
    "XOR_X = [[0,0],[0,1],[1,0],[1,1]]\n",
    "XOR_Y = [[0],[1],[1],[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating placeholders for datasets.\n",
    "\n",
    "x_ = tf.placeholder(tf.float32, shape=[4,2], name = 'x-input')\n",
    "y_ = tf.placeholder(tf.float32, shape=[4,1], name = 'y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating weights and biases\n",
    "\n",
    "Theta1 = tf.Variable(tf.random_uniform([2,2], -1, 1), name = \"Theta1\")\n",
    "Theta2 = tf.Variable(tf.random_uniform([2,1], -1, 1), name = \"Theta2\")\n",
    "\n",
    "Bias1 = tf.Variable(tf.zeros([2]), name = \"Bias1\")\n",
    "Bias2 = tf.Variable(tf.zeros([1]), name = \"Bias2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# hidden layer 1\n",
    "with tf.name_scope(\"layer1\") as scope:\n",
    "    l1 = tf.sigmoid(tf.matmul(x_, Theta1) + Bias1)\n",
    "\n",
    "# result\n",
    "with tf.name_scope(\"result\") as scope:\n",
    "    res = tf.sigmoid(tf.matmul(l1, Theta2) + Bias2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining cost function = log loss\n",
    "\n",
    "with tf.name_scope(\"cost\") as scope:\n",
    "    cost = tf.reduce_mean(( (y_ * tf.log(res)) + \n",
    "        ((1 - y_) * tf.log(1.0 - res)) ) * -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining training operation.\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cost)# learning rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initilising variables and session.\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Result  [[0.50444573]\n",
      " [0.46721   ]\n",
      " [0.5338455 ]\n",
      " [0.48817047]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 0.41925806 -0.67719144]\n",
      " [-0.9397586   0.9431765 ]]\n",
      "Bias1  [-0.3093442   0.73071647]\n",
      "layer_1 output  [[0.42327482 0.67496246]\n",
      " [0.22285551 0.8420942 ]\n",
      " [0.5274508  0.5133781 ]\n",
      " [0.30367792 0.73040956]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[ 0.29440463]\n",
      " [-0.539261  ]]\n",
      "Bias2  [0.25715026]\n",
      "cost  0.6901169\n",
      "Epoch  1000\n",
      "Result  [[0.5029123]\n",
      " [0.4559212]\n",
      " [0.5467775]\n",
      " [0.4833581]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 0.4713181 -0.8556909]\n",
      " [-0.9838123  1.1577609]]\n",
      "Bias1  [-0.38275626  0.88824546]\n",
      "layer_1 output  [[0.4054623  0.708528  ]\n",
      " [0.2031748  0.88554347]\n",
      " [0.522126   0.50813794]\n",
      " [0.29002753 0.7667975 ]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[ 0.33199778]\n",
      " [-0.6850503 ]]\n",
      "Bias2  [0.36241412]\n",
      "cost  0.6871357\n",
      "Epoch  2000\n",
      "Result  [[0.49759996]\n",
      " [0.4376858 ]\n",
      " [0.57075053]\n",
      " [0.4741183 ]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 0.5300355 -1.162544 ]\n",
      " [-1.0329311  1.5014267]]\n",
      "Bias1  [-0.47212768  1.111963  ]\n",
      "layer_1 output  [[0.38411278 0.75249493]\n",
      " [0.18167225 0.93171835]\n",
      " [0.5144729  0.48735744]\n",
      " [0.27388042 0.81012857]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[ 0.3663199]\n",
      " [-0.9306891]]\n",
      "Bias2  [0.55003047]\n",
      "cost  0.67952365\n",
      "Epoch  3000\n",
      "Result  [[0.4826902 ]\n",
      " [0.41029036]\n",
      " [0.61738575]\n",
      " [0.45618206]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 0.5823492 -1.6778033]\n",
      " [-1.0756848  2.042193 ]]\n",
      "Bias1  [-0.57385516  1.4163486 ]\n",
      "layer_1 output  [[0.36034775 0.80476534]\n",
      " [0.16117114 0.9694848 ]\n",
      " [0.5021235  0.43500614]\n",
      " [0.2559377  0.855788  ]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[ 0.3638845]\n",
      " [-1.3418019]]\n",
      "Bias2  [0.87944376]\n",
      "cost  0.6603514\n",
      "Epoch  4000\n",
      "Result  [[0.45317236]\n",
      " [0.38026872]\n",
      " [0.69294626]\n",
      " [0.4278166 ]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 0.60071504 -2.3917544 ]\n",
      " [-1.0919409   2.7760682 ]]\n",
      "Bias1  [-0.66829294  1.8011909 ]\n",
      "layer_1 output  [[0.33887923 0.85829383]\n",
      " [0.14676103 0.98982155]\n",
      " [0.48311195 0.35650557]\n",
      " [0.23875475 0.89894027]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[ 0.24599108]\n",
      " [-1.9257342 ]]\n",
      "Bias2  [1.3816234]\n",
      "cost  0.62389934\n",
      "Epoch  5000\n",
      "Result  [[0.4168662 ]\n",
      " [0.36216784]\n",
      " [0.7726609 ]\n",
      " [0.39915022]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 0.5944097 -3.1298962]\n",
      " [-1.0892042  3.5454197]]\n",
      "Bias1  [-0.7041245  2.2236729]\n",
      "layer_1 output  [[0.3308984  0.9023553 ]\n",
      " [0.14266509 0.9968871 ]\n",
      " [0.4725988  0.2877733 ]\n",
      " [0.23166761 0.933342  ]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[-0.05700969]\n",
      " [-2.549907  ]]\n",
      "Bias2  [1.9841353]\n",
      "cost  0.58057785\n",
      "Epoch  6000\n",
      "Result  [[0.38319144]\n",
      " [0.36081836]\n",
      " [0.82775074]\n",
      " [0.37822717]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 0.68181545 -3.7641904 ]\n",
      " [-1.1221949   4.2108617 ]]\n",
      "Bias1  [-0.58632946  2.6056488 ]\n",
      "layer_1 output  [[0.35747752 0.9312242 ]\n",
      " [0.15335518 0.99890566]\n",
      " [0.52385336 0.2389324 ]\n",
      " [0.2637227  0.9548826 ]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[-0.55475956]\n",
      " [-3.0884256 ]]\n",
      "Bias2  [2.598307]\n",
      "cost  0.5417002\n",
      "Epoch  7000\n",
      "Result  [[0.3522585 ]\n",
      " [0.39168185]\n",
      " [0.8412378 ]\n",
      " [0.34187713]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 1.1861085 -4.3239565]\n",
      " [-1.2379963  4.7572193]]\n",
      "Bias1  [-0.118908   2.8805833]\n",
      "layer_1 output  [[0.47030798 0.94687825]\n",
      " [0.20474389 0.9995184 ]\n",
      " [0.7440641  0.1910235 ]\n",
      " [0.45740452 0.96490085]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[-1.3283128]\n",
      " [-3.4930346]]\n",
      "Bias2  [3.3230681]\n",
      "cost  0.49070334\n",
      "Epoch  8000\n",
      "Result  [[0.3005213 ]\n",
      " [0.526766  ]\n",
      " [0.8216465 ]\n",
      " [0.24791797]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 2.354491  -4.9005566]\n",
      " [-1.9369401  5.1984587]]\n",
      "Bias1  [0.6741075 3.0066323]\n",
      "layer_1 output  [[0.6624223  0.9528729 ]\n",
      " [0.22048664 0.9997267 ]\n",
      " [0.9538495  0.13079768]\n",
      " [0.7486938  0.96458405]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[-2.5561447]\n",
      " [-3.7919762]]\n",
      "Bias2  [4.461702]\n",
      "cost  0.3699434\n",
      "Epoch  9000\n",
      "Result  [[0.2032884 ]\n",
      " [0.70571744]\n",
      " [0.8290326 ]\n",
      " [0.16480394]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 3.4420283 -5.3915925]\n",
      " [-3.01859    5.5553565]]\n",
      "Bias1  [1.3685569 3.060365 ]\n",
      "layer_1 output  [[0.7971469  0.95522785]\n",
      " [0.16110444 0.9998188 ]\n",
      " [0.9919226  0.08856952]\n",
      " [0.8571718  0.96173227]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[-3.8210375]\n",
      " [-4.256463 ]]\n",
      "Bias2  [5.745953]\n",
      "cost  0.23584688\n",
      "Epoch  10000\n",
      "Result  [[0.13874428]\n",
      " [0.8093597 ]\n",
      " [0.85902435]\n",
      " [0.11527997]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 4.170504  -5.732752 ]\n",
      " [-3.7795835  5.841362 ]]\n",
      "Bias1  [1.8189893 3.113545 ]\n",
      "layer_1 output  [[0.86044484 0.957448  ]\n",
      " [0.12340274 0.9998709 ]\n",
      " [0.9975013  0.06791246]\n",
      " [0.9011359  0.96165955]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[-4.7157383]\n",
      " [-4.8107023]]\n",
      "Bias2  [6.8378716]\n",
      "cost  0.15882942\n",
      "Epoch  11000\n",
      "Result  [[0.10228912]\n",
      " [0.86294585]\n",
      " [0.88649803]\n",
      " [0.08650575]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 4.657076  -5.972083 ]\n",
      " [-4.2863183  6.0684395]]\n",
      "Bias1  [2.1046739 3.1716661]\n",
      "layer_1 output  [[0.8913566  0.959754  ]\n",
      " [0.10141096 0.99990296]\n",
      " [0.99884415 0.05730167]\n",
      " [0.9224014  0.96331537]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[-5.3493276]\n",
      " [-5.3215985]]\n",
      "Bias2  [7.703539]\n",
      "cost  0.116566285\n",
      "Epoch  12000\n",
      "Result  [[0.08003724]\n",
      " [0.8939948 ]\n",
      " [0.9070303 ]\n",
      " [0.06842866]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 5.0057006 -6.1518455]\n",
      " [-4.6479263  6.2509027]]\n",
      "Bias1  [2.3015146 3.2267911]\n",
      "layer_1 output  [[0.9090024  0.96183014]\n",
      " [0.08735138 0.99992347]\n",
      " [0.9993297  0.05092886]\n",
      " [0.9345812  0.965305  ]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[-5.8339453]\n",
      " [-5.7599077]]\n",
      "Bias2  [8.401282]\n",
      "cost  0.09098483\n",
      "Epoch  13000\n",
      "Result  [[0.06532007]\n",
      " [0.91395587]\n",
      " [0.92205477]\n",
      " [0.05623994]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 5.270991  -6.2944603]\n",
      " [-4.9222093  6.4007   ]]\n",
      "Bias1  [2.4473777 3.2763066]\n",
      "layer_1 output  [[0.9203695  0.9636071 ]\n",
      " [0.07764152 0.9999373 ]\n",
      " [0.99955565 0.04661244]\n",
      " [0.9424679  0.9671546 ]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[-6.2258086]\n",
      " [-6.1336236]]\n",
      "Bias2  [8.979543]\n",
      "cost  0.074139535\n",
      "Epoch  14000\n",
      "Result  [[0.05496485]\n",
      " [0.92778337]\n",
      " [0.9332558 ]\n",
      " [0.04755425]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 5.482091  -6.412053 ]\n",
      " [-5.1398773  6.5264034]]\n",
      "Bias1  [2.5613503 3.3202052]\n",
      "layer_1 output  [[0.9283324  0.9651154 ]\n",
      " [0.07053325 0.9999471 ]\n",
      " [0.99967885 0.04344475]\n",
      " [0.94802237 0.96876717]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[-6.554583]\n",
      " [-6.455653]]\n",
      "Bias2  [9.470755]\n",
      "cost  0.06232206\n",
      "Epoch  15000\n",
      "Result  [[0.04732636]\n",
      " [0.93789184]\n",
      " [0.9418258 ]\n",
      " [0.04109137]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 5.655748  -6.5117435]\n",
      " [-5.3185263  6.6339526]]\n",
      "Bias1  [2.6539023 3.3591824]\n",
      "layer_1 output  [[0.93425107 0.96640426]\n",
      " [0.06509334 0.99995434]\n",
      " [0.99975395 0.04099053]\n",
      " [0.95217156 0.9701536 ]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[-6.8376393]\n",
      " [-6.7369523]]\n",
      "Bias2  [9.896486]\n",
      "cost  0.0536245\n",
      "Epoch  16000\n",
      "Result  [[0.04148149]\n",
      " [0.94558585]\n",
      " [0.9485487 ]\n",
      " [0.03611507]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 5.802267  -6.5980315]\n",
      " [-5.468953   6.7274847]]\n",
      "Bias1  [2.7312498 3.394002 ]\n",
      "layer_1 output  [[0.93884563 0.96751654]\n",
      " [0.06078488 0.9999598 ]\n",
      " [0.99980325 0.03901434]\n",
      " [0.95540714 0.9713478 ]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[-7.0860324]\n",
      " [-6.9858603]]\n",
      "Bias2  [10.271484]\n",
      "cost  0.04698063\n",
      "Epoch  17000\n",
      "Result  [[0.03687662]\n",
      " [0.95162773]\n",
      " [0.953941  ]\n",
      " [0.03217617]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 5.9283648 -6.6739354]\n",
      " [-5.5981874  6.809951 ]]\n",
      "Bias1  [2.797334  3.4253354]\n",
      "layer_1 output  [[0.9425316  0.968487  ]\n",
      " [0.05727807 0.9999641 ]\n",
      " [0.99983764 0.03737721]\n",
      " [0.9580134  0.97238386]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[-7.307238]\n",
      " [-7.208636]]\n",
      "Bias2  [10.606169]\n",
      "cost  0.041753456\n",
      "Epoch  18000\n",
      "Result  [[0.03316206]\n",
      " [0.95649177]\n",
      " [0.9583502 ]\n",
      " [0.02898731]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 6.0386167 -6.7415757]\n",
      " [-5.711011   6.883506 ]]\n",
      "Bias1  [2.8547852 3.4537425]\n",
      "layer_1 output  [[0.9455656  0.9693426 ]\n",
      " [0.05436042 0.9999676 ]\n",
      " [0.9998627  0.03599095]\n",
      " [0.9601662  0.97329074]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[-7.506553]\n",
      " [-7.409989]]\n",
      "Bias2  [10.908132]\n",
      "cost  0.037541308\n",
      "Epoch  19000\n",
      "Result  [[0.03010655]\n",
      " [0.9604881 ]\n",
      " [0.9620154 ]\n",
      " [0.02635665]]\n",
      "Layer 1 values:-\n",
      "Theta1  [[ 6.136276 -6.802489]\n",
      " [-5.810813  6.949754]]\n",
      "Bias1  [2.9054396 3.479668 ]\n",
      "layer_1 output  [[0.94811463 0.97010374]\n",
      " [0.05188859 0.9999704 ]\n",
      " [0.9998816  0.03479654]\n",
      " [0.9619807  0.9740915 ]]\n",
      "Layer 2 values:-\n",
      "Theta2  [[-7.6878753]\n",
      " [-7.593516 ]]\n",
      "Bias2  [11.183042]\n",
      "cost  0.034079447\n",
      "Elapsed time  7.647713000000001\n"
     ]
    }
   ],
   "source": [
    "# Training the model - Forward Propagation\n",
    "\n",
    "t_start = time.clock()\n",
    "for i in range(20000):\n",
    "    sess.run(train_step, feed_dict={x_: XOR_X, y_: XOR_Y})\n",
    "    if i % 1000 == 0:\n",
    "        print('Epoch ', i)\n",
    "        print('Layer 1 values:-')\n",
    "        print('Theta1 ', sess.run(Theta1))\n",
    "        print('Bias1 ', sess.run(Bias1))\n",
    "        print('layer_1 output ', sess.run(l1, feed_dict={x_: XOR_X, y_: XOR_Y}))\n",
    "        print('Result ', sess.run(res, feed_dict={x_: XOR_X, y_: XOR_Y}))\n",
    "        print('Theta2 ', sess.run(Theta2))\n",
    "        print('Bias2 ', sess.run(Bias2))\n",
    "        print('cost ', sess.run(cost, feed_dict={x_: XOR_X, y_: XOR_Y}))\n",
    "t_end = time.clock()\n",
    "\n",
    "print('Elapsed time ', t_end - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As seen above, for a XOR operation where the outputs were not linearly separable, \n",
    "# we were able to solve by applying multi layer perceptrons."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
