{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoders tutorial\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#visualizing digits\n",
    "first_image = x_train[-1]\n",
    "plt.imshow(first_image, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#reshaping and normalizing input\n",
    "train_x = x_train.reshape(60000, 784) / 255\n",
    "val_x = x_test.reshape(10000, 784) / 255\n",
    "\n",
    "#building a simple autoencoder model\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(392,  activation='sigmoid', name=\"bottleneck\", input_shape=(784,)))\n",
    "autoencoder.add(Dense(784,  activation='sigmoid'))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer = Adam())\n",
    "trained_model = autoencoder.fit(train_x, train_x, batch_size=1024, epochs=10)\n",
    "encoder = Model(autoencoder.input, autoencoder.get_layer('bottleneck').output)\n",
    "encoded_data = encoder.predict(train_x)  # bottleneck representation\n",
    "decoded_output = autoencoder.predict(train_x)        # reconstruction\n",
    "\n",
    "#visualize decoded output\n",
    "pixels = decoded_output[-1].reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#building a decent autoencoder model\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(512,  activation='elu', input_shape=(784,)))\n",
    "autoencoder.add(Dense(128,  activation='elu'))\n",
    "autoencoder.add(Dense(10,    activation='linear', name=\"bottleneck\"))\n",
    "autoencoder.add(Dense(128,  activation='elu'))\n",
    "autoencoder.add(Dense(512,  activation='elu'))\n",
    "autoencoder.add(Dense(784,  activation='sigmoid'))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer = Adam())\n",
    "trained_model = autoencoder.fit(train_x, train_x, batch_size=1024, epochs=10)\n",
    "encoder = Model(autoencoder.input, autoencoder.get_layer('bottleneck').output)\n",
    "encoded_data = encoder.predict(train_x)  # bottleneck representation\n",
    "decoded_output = autoencoder.predict(train_x)        # reconstruction\n",
    "\n",
    "#visualize decoded layer\n",
    "pixels = decoded_output[-1].reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# return the decoder\n",
    "encoding_dim = 10\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder = autoencoder.layers[-3](encoded_input)\n",
    "decoder = autoencoder.layers[-2](decoder)\n",
    "decoder = autoencoder.layers[-1](decoder)\n",
    "decoder = Model(encoded_input, decoder)\n",
    "\n",
    "\n",
    "###################Denoising############################\n",
    "# The code below is from the Keras Blogs\n",
    "# https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D, UpSampling2D\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "#Print one image to see the noise\n",
    "plt.imshow(x_train_noisy[-1].reshape(28, 28),cmap='gray')\n",
    "\n",
    "\n",
    "#encoding\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "nn = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "nn = MaxPooling2D((2, 2), padding='same')(nn)\n",
    "nn = Conv2D(32, (3, 3), activation='relu', padding='same')(nn)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(nn)\n",
    "\n",
    "#decoding\n",
    "nn = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "nn = UpSampling2D((2, 2))(nn)\n",
    "nn = Conv2D(32, (3, 3), activation='relu', padding='same')(nn)\n",
    "nn = UpSampling2D((2, 2))(nn)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(nn)\n",
    "\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta',loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                validation_data=(x_test_noisy, x_test))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
